{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d8d3ceb5-212c-44cd-9161-4fceebedddeb",
   "metadata": {},
   "source": [
    "# Introduction to Natural Language Processing (NLP)\n",
    "\n",
    "## What is NLP?\n",
    "Natural Language Processing (NLP) is a subfield of Artificial Intelligence (AI) that focuses on the interaction between computers and humans through natural language. The goal of NLP is to enable machines to understand, interpret, and respond to text and spoken language in a way that is both meaningful and useful.\n",
    "\n",
    "---\n",
    "\n",
    "## Applications of NLP\n",
    "NLP has a wide range of applications across various industries, including:\n",
    "\n",
    "- **Sentiment Analysis**: Determining the sentiment (positive, negative, neutral) in text.\n",
    "- **Machine Translation**: Translating text from one language to another (e.g., Google Translate).\n",
    "- **Chatbots and Virtual Assistants**: Developing conversational agents like Siri, Alexa, or ChatGPT.\n",
    "- **Text Summarization**: Automatically generating summaries of large documents or articles.\n",
    "- **Speech Recognition**: Converting spoken language into text (e.g., voice-to-text services).\n",
    "- **Named Entity Recognition (NER)**: Identifying entities like names, dates, locations, etc., in a text.\n",
    "\n",
    "---\n",
    "\n",
    "## Key Concepts in NLP\n",
    "- **Tokenization**: Breaking text into smaller units such as words or sentences.\n",
    "- **Part-of-Speech Tagging**: Identifying the grammatical role of each word in a sentence.\n",
    "- **Dependency Parsing**: Analyzing grammatical structure and relationships between words.\n",
    "- **Word Embeddings**: Representing words as vectors in a continuous vector space (e.g., Word2Vec, GloVe).\n",
    "- **Transformer Models**: State-of-the-art models like BERT, GPT, and T5 for advanced NLP tasks.\n",
    "\n",
    "---\n",
    "\n",
    "## Popular NLP Libraries and Frameworks\n",
    "- **NLTK**: Natural Language Toolkit for basic NLP tasks.\n",
    "- **spaCy**: Industrial-strength NLP library with efficient pipelines.\n",
    "- **Hugging Face Transformers**: A library for state-of-the-art transformer models.\n",
    "- **Gensim**: For topic modeling and similarity analysis.\n",
    "- **StanfordNLP**: Suite of NLP tools from Stanford University.\n",
    "\n",
    "---\n",
    "\n",
    "## Challenges in NLP\n",
    "- **Ambiguity**: Understanding context when words or phrases have multiple meanings.\n",
    "- **Sarcasm and Humor**: Interpreting non-literal or complex language patterns.\n",
    "- **Multilingual Processing**: Supporting a wide variety of languages with different structures.\n",
    "- **Data Availability**: Ensuring diverse and unbiased datasets for training.\n",
    "\n",
    "---\n",
    "\n",
    "## Getting Started with NLP\n",
    "To begin exploring NLP:\n",
    "1. Learn basic Python programming.\n",
    "2. Install libraries like `nltk`, `spaCy`, or `transformers`.\n",
    "3. Work on simple tasks like text preprocessing, tokenization, and sentiment analysis.\n",
    "4. Experiment with pre-trained models from Hugging Face for advanced projects.\n",
    "\n",
    "---\n",
    "\n",
    "### Example: Tokenization with NLTK\n",
    "```python\n",
    "import nltk\n",
    "from nltk.tokenize import word_tokenize\n",
    "\n",
    "# Example text\n",
    "text = \"Natural Language Processing is fascinating!\"\n",
    "# Tokenize text\n",
    "tokens = word_tokenize(text)\n",
    "print(tokens)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "15ab1404-6994-4f53-b2da-f3861ce26ab5",
   "metadata": {},
   "outputs": [],
   "source": [
    "%config Completer.use_jedi = False\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88eb5479-8478-4d30-a803-b4e07ad5a4c1",
   "metadata": {},
   "source": [
    "# NLP Pipeline\n",
    "\n",
    "**Data Collection** -> **Text Cleaning** -> **Pre-processing** -> **Feature Engineering** -> **Modeling** -> **Evalution** -> **Deployment** -> **Monitor and Model update**\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f84ef159-823e-4b0c-bb4f-ffcb06ae19cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x = \"Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence. It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "dfb8e31d-1f01-4fc3-a39e-1af8e61ab04f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "073286f8-b05e-4267-8145-0444f3b82db9",
   "metadata": {},
   "outputs": [],
   "source": [
    "w = word_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a90e4516-b72e-461d-81ae-a81ae7f88970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Natural', 'language', 'processing', '(', 'NLP', ')', 'is', 'a', 'subfield', 'of', 'computer', 'science', 'and', 'especially', 'artificial', 'intelligence', '.', 'It', 'is', 'primarily', 'concerned', 'with', 'providing', 'computers', 'with', 'the', 'ability', 'to', 'process', 'data', 'encoded', 'in', 'natural', 'language', 'and', 'is', 'thus', 'closely', 'related', 'to', 'information', 'retrieval', ',', 'knowledge', 'representation', 'and', 'computational', 'linguistics', ',', 'a', 'subfield', 'of', 'linguistics', '.']\n"
     ]
    }
   ],
   "source": [
    "print(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "fdfbf119-ca46-42d3-a484-64485cfcdfb6",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import pos_tag "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d073027f-4471-4846-bf59-cb25aadc7f4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "p = pos_tag(w)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "574d8e00-4aa1-43cb-9a69-8d72ef171824",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Natural', 'JJ'), ('language', 'NN'), ('processing', 'NN'), ('(', '('), ('NLP', 'NNP'), (')', ')'), ('is', 'VBZ'), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('computer', 'NN'), ('science', 'NN'), ('and', 'CC'), ('especially', 'RB'), ('artificial', 'JJ'), ('intelligence', 'NN'), ('.', '.'), ('It', 'PRP'), ('is', 'VBZ'), ('primarily', 'RB'), ('concerned', 'VBN'), ('with', 'IN'), ('providing', 'VBG'), ('computers', 'NNS'), ('with', 'IN'), ('the', 'DT'), ('ability', 'NN'), ('to', 'TO'), ('process', 'VB'), ('data', 'NNS'), ('encoded', 'VBN'), ('in', 'IN'), ('natural', 'JJ'), ('language', 'NN'), ('and', 'CC'), ('is', 'VBZ'), ('thus', 'RB'), ('closely', 'RB'), ('related', 'JJ'), ('to', 'TO'), ('information', 'NN'), ('retrieval', 'NN'), (',', ','), ('knowledge', 'NN'), ('representation', 'NN'), ('and', 'CC'), ('computational', 'JJ'), ('linguistics', 'NNS'), (',', ','), ('a', 'DT'), ('subfield', 'NN'), ('of', 'IN'), ('linguistics', 'NNS'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "print(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c216521f-adc3-49d8-ab34-f6565a54cce0",
   "metadata": {},
   "source": [
    "# Part of Speech \n",
    "JJ means Adjustive \n",
    "NN menas Noun, singular\n",
    "etc..."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "073e49e0-051d-48a0-b1ec-421435334435",
   "metadata": {},
   "source": [
    "# Text-Processing Techniques\n",
    "\n",
    "- Tokenization\n",
    "- Stop word removal\n",
    "- N-grams\n",
    "- Stemming\n",
    "- Word Sentence\n",
    "- Count vectorization\n",
    "- Lemmatization\n",
    "- TF-IDF vectorizitaion\n",
    "- Hashing vector"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "93e0aa66-e489-4f07-ba30-9d857f60c672",
   "metadata": {},
   "source": [
    "# Tokenization\n",
    "\n",
    "used in natural language processing to split paragraphs and sentence into smaller unites that can be more easily assigned meaning."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a979557f-fd22-448a-be70-1df22a304bc8",
   "metadata": {},
   "source": [
    "we can mainly tokenize 3 stuff : word, sentence and character"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd957d68-6a3c-431d-9e31-e494a490ae6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize, word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9c78f9eb-e5f2-4b3e-aba1-6d8d23f68ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = sent_tokenize(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "425c72e3-dd92-4330-939f-0b2332a017e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence.',\n",
       " 'It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.']"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "55ab00e7-b09e-4e9c-9e83-760756649b45",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural language processing (NLP) is a subfield of computer science and especially artificial intelligence.\n",
      "\n",
      "It is primarily concerned with providing computers with the ability to process data encoded in natural language and is thus closely related to information retrieval, knowledge representation and computational linguistics, a subfield of linguistics.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# look more clear\n",
    "for i in sentence:\n",
    "    print(i)\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "843b9df1-246a-4107-bbff-afd293a8f9e1",
   "metadata": {},
   "source": [
    "# Stop word Removal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "2fb5179b-2b7b-42eb-803a-86a243789295",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords\n",
    "from string import punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "ce22a733-8cfe-47a0-9890-96c6294e4309",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "36a25a77-a701-4bb7-a41b-6fa68fddcf1d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stop = stopwords.words(\"english\")\n",
    "stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "e05480d6-b034-48f7-95af-2a3dd1b3a479",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_word = list(punctuation) + stop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "a054c554-2667-44c3-89a0-84d61e666b9e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Natural\n",
      "language\n",
      "processing\n",
      "NLP\n",
      "subfield\n",
      "computer\n",
      "science\n",
      "especially\n",
      "artificial\n",
      "intelligence\n",
      "It\n",
      "primarily\n",
      "concerned\n",
      "providing\n",
      "computers\n",
      "ability\n",
      "process\n",
      "data\n",
      "encoded\n",
      "natural\n",
      "language\n",
      "thus\n",
      "closely\n",
      "related\n",
      "information\n",
      "retrieval\n",
      "knowledge\n",
      "representation\n",
      "computational\n",
      "linguistics\n",
      "subfield\n",
      "linguistics\n"
     ]
    }
   ],
   "source": [
    "# w is word tokenized form that we do before\n",
    "for i in w:\n",
    "    if i not in stop_word:\n",
    "        print(i)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "158a7819-e321-4933-ad94-20dc1bd3cd49",
   "metadata": {},
   "source": [
    "# Stemming and Lemmatization\n",
    "\n",
    "example:\n",
    "1. changing -> chang\n",
    "2. changed  -> chang\n",
    "3. change   -> change"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "fa6f049f-689b-4b32-8706-ee1a31803438",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import LancasterStemmer, RegexpStemmer, PorterStemmer, SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "426f9086-f4e6-4950-bbc9-15c501f52079",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = LancasterStemmer()\n",
    "r = RegexpStemmer('ing')\n",
    "p = PorterStemmer()\n",
    "s = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "fc219de2-eab0-429a-b548-3d202fd7c2b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.stem(\"changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f222c646-aa07-4f15-8722-6738ba2cf8b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'changed'"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r.stem(\"changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "11e40a3a-3947-4f54-9420-537990640db4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p.stem(\"changed\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "5a632c9a-f0b2-4d5c-9135-e982b8bf3187",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'chang'"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "s.stem(\"changed\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1730d062-d5a3-49aa-a292-98ebd7d71a5e",
   "metadata": {},
   "source": [
    "# Lemmatizations\n",
    "\n",
    "example:\n",
    "1. Studying -> study\n",
    "2. Studies  -> study\n",
    "3. Study    -> study"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "618772f4-cd34-48ab-b084-bb687caddf10",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "323e0453-faea-4842-9fcb-c4e952932903",
   "metadata": {},
   "outputs": [],
   "source": [
    "wl = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "a9111060-0e85-4229-9e6c-541ed81e154a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mouse'"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize(\"mice\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "65f377a6-ef16-4e07-aba9-5972f1a2f796",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'heylo'"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wl.lemmatize(\"heylo\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f9e27a3-1302-4556-a6c6-e2c2e15d1620",
   "metadata": {},
   "source": [
    "# N Grams\n",
    "\n",
    "continues sequence of words or symbols or tokens in document (Auto-suggestions)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d42d93c-ea10-4166-9e48-05e84fa300ee",
   "metadata": {},
   "source": [
    "# Steps for Generating N-Grams\n",
    "\n",
    "## What is an N-Gram?\n",
    "An **N-Gram** is a contiguous sequence of `N` items (words, characters, etc.) from a given text or speech. N-Grams are commonly used in Natural Language Processing (NLP) for tasks such as text prediction, machine translation, and more.\n",
    "\n",
    "---\n",
    "\n",
    "## Steps to Generate N-Grams\n",
    "1. **Input Text**: Start with a string of text.\n",
    "2. **Tokenization**: Break the text into individual units (words or characters).\n",
    "3. **Sliding Window**: Use a sliding window of size `N` over the tokens to extract groups of `N` consecutive elements.\n",
    "4. **Output N-Grams**: Return the generated n-grams as a list.\n",
    "\n",
    "---\n",
    "\n",
    "## Example: Generating N-Grams\n",
    "### Input\n",
    "```text\n",
    "\"I love natural language processing.\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07078f06-a77e-4f1a-a25c-73017f857884",
   "metadata": {},
   "outputs": [],
   "source": [
    "example = \"i am dhruv, i am software engineer\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "44bb7ec0-ceff-4be1-b16b-6cbe0f58fcf9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'am', 'dhruv', ',', 'i', 'am', 'software', 'engineer']"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokens = word_tokenize(example)\n",
    "word_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "3690fc70-fd07-4267-a819-44014de31787",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.collocations import BigramCollocationFinder, TrigramCollocationFinder, ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "e7f00fb0-d35d-4a4f-9615-68ce7f5f979e",
   "metadata": {},
   "outputs": [],
   "source": [
    "b = BigramCollocationFinder.from_words(word_tokens)\n",
    "t = TrigramCollocationFinder.from_words(word_tokens)\n",
    "n = ngrams(word_tokens, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "fe00447e-f5bb-4a3a-a3e4-8e88cfbca357",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('i', 'am')\n",
      "('am', 'dhruv')\n",
      "('dhruv', ',')\n",
      "(',', 'i')\n",
      "('i', 'am')\n",
      "('am', 'software')\n",
      "('software', 'engineer')\n"
     ]
    }
   ],
   "source": [
    "# b.ngram_fd\n",
    "# t.ngram_fd\n",
    "# n # it return zip file so we have to iterate\n",
    "for i in n:\n",
    "    print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "06db7fad-401b-4b0e-b7c2-744046ceca85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys([('i', 'am', 'dhruv'), ('am', 'dhruv', ','), ('dhruv', ',', 'i'), (',', 'i', 'am'), ('i', 'am', 'software'), ('am', 'software', 'engineer')])"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# b.ngram_fd.keys()\n",
    "t.ngram_fd.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ff9444a-3633-4ef6-a3d2-c96fa4b8ad43",
   "metadata": {},
   "source": [
    "# Count Vectorizations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "470308ce-12f6-4752-b4bc-3e15dab0541e",
   "metadata": {},
   "outputs": [],
   "source": [
    "lst = [\"hi dhruv\", \"hi rni\", \"rni teach dhruv data science\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "5429f2ed-fc68-4eca-8460-94c5154b8cd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "70b39aeb-0920-4536-9fac-9d773ad89556",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>name</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hi dhruv</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>hi rni</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>rni teach dhruv data science</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                           name\n",
       "0                      hi dhruv\n",
       "1                        hi rni\n",
       "2  rni teach dhruv data science"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame({\"name\": lst})\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "bc75ce08-bdf1-43c8-aba4-9b424b7d5012",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'sklearn'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[76], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msklearn\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mfeature_extraction\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtext\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m CountVectorizer\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'sklearn'"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "5ac920cc-2de9-41ae-ad2e-127cf1ed7e4a",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'CountVectorizer' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[68], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m cv \u001b[38;5;241m=\u001b[39m \u001b[43mCountVectorizer\u001b[49m()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'CountVectorizer' is not defined"
     ]
    }
   ],
   "source": [
    "cv = CountVectorizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "59a30016-24b7-4626-8217-e82f76f244b2",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[72], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m new_data \u001b[38;5;241m=\u001b[39m \u001b[43mcv\u001b[49m\u001b[38;5;241m.\u001b[39mfit_transform(df[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mname\u001b[39m\u001b[38;5;124m\"\u001b[39m])\u001b[38;5;241m.\u001b[39mtoarray()\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "new_data = cv.fit_transform(df[\"name\"]).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ddc9184f-86a7-4fb1-96b8-5da9384ceefa",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'cv' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[73], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m \u001b[43mcv\u001b[49m\u001b[38;5;241m.\u001b[39mvocabulary_\n",
      "\u001b[1;31mNameError\u001b[0m: name 'cv' is not defined"
     ]
    }
   ],
   "source": [
    "cv.vocabulary_"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f8130fa-48d6-46ff-8560-9f8234a2aca1",
   "metadata": {},
   "source": [
    "# Word Sense Disambiguations\n",
    "\n",
    "like mousr have 2 meaning -> one is computer mouse and other mice"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "88f28267-b5d9-42cc-ae22-3f2e71afc19c",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.wsd import lesk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "63407a88-1cf3-46c8-b284-79910f14874a",
   "metadata": {},
   "outputs": [],
   "source": [
    "l = lesk(word_tokens, \"NLP\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "aad6b524-472f-4c31-99d3-ceab548e9636",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Synset('natural_language_processing.n.01')"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "38894372-7d2a-46f5-b2df-8cf71d281c42",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'the branch of information science that deals with natural language information'"
      ]
     },
     "execution_count": 81,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "l.definition()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87d35ec1-e91a-4beb-9dc3-15d2488171a2",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15e1865b-6cf1-4833-bad5-7bda9272b21c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cac2cdfd-dafe-43a8-baf5-f704a0d92c52",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e04dc4cf-9aac-4002-945e-20bfe8345498",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69a9aec-7ebb-4ff5-9882-0b961cb6657b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a8d5885-d0e8-4641-a3df-3cc96961649e",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88c8b190-f7b4-4b4b-9e1b-b31e73b46a5c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c82a819-e4c2-4ab7-9037-7b22143b7898",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
